{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the distributed seismicity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cleaner avoid to restart kernel for each code modification, use it just when alone\n",
    "from cleaner import modules_cleaner; modules_cleaner()\n",
    "# load current project if secondary ipynb runned alone\n",
    "import metys; metys.Metys.secondary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy\n",
    "import scipy\n",
    "import cPickle as pickle\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from mbt.tools.area import create_catalogue\n",
    "from mbt.tools.smooth import Smoothing\n",
    "from mbt.tools.geo import get_idx_points_inside_polygon\n",
    "from mbt.sources import OQtSource\n",
    "\n",
    "from openquake.hazardlib.source import PointSource, SimpleFaultSource\n",
    "from openquake.hazardlib.mfd.evenly_discretized import EvenlyDiscretizedMFD\n",
    "from openquake.hazardlib.geo.point import Point\n",
    "from openquake.hazardlib.geo.geodetic import azimuth, point_at\n",
    "\n",
    "from openquake.hazardlib.sourcewriter import write_source_model\n",
    "\n",
    "from hmtk.seismicity.selector import CatalogueSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(area_source_ids_list) > 1:\n",
    "    assert 0 == 1\n",
    "    \n",
    "# Load sources\n",
    "model_key = metys.g_prj.models.current \n",
    "data_path = os.path.join(metys.g_prj.folder, '%s_area_sources.pkl' % model_key)\n",
    "fin = open(data_path,'rb') \n",
    "asources = pickle.load(fin)\n",
    "fin.close()\n",
    "\n",
    "data_path = os.path.join(metys.g_prj.folder, '%s_fault_sources.pkl' % model_key)\n",
    "fin = open(data_path,'rb') \n",
    "fsources = pickle.load(fin)\n",
    "fin.close()\n",
    "    \n",
    "# Get source data\n",
    "src = asources[area_source_ids_list[0]]\n",
    "print 'Processing area source with ID:', area_source_ids_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dist_seism_threshold_magnitude = 6.5\n",
    "\n",
    "def get_xy(line):\n",
    "    x = []\n",
    "    y = []\n",
    "    for pnt in line.points:\n",
    "        x.append(pnt.longitude)\n",
    "        y.append(pnt.latitude)\n",
    "    return x, y \n",
    "\n",
    "\n",
    "def get_polygon_from_simple_fault(flt):\n",
    "\n",
    "    xtrace = []\n",
    "    ytrace = []\n",
    "    \n",
    "    if isinstance(flt, SimpleFaultSource):\n",
    "        trc = flt.fault_trace\n",
    "    elif isinstance(flt, OQtSource):\n",
    "        trc = flt.trace\n",
    "        \n",
    "    for pnt in trc:\n",
    "        xtrace.append(pnt.longitude)\n",
    "        ytrace.append(pnt.latitude)\n",
    "\n",
    "    # Get strike direction\n",
    "    azim = azimuth(xtrace[0], ytrace[0],\n",
    "                   xtrace[-1], ytrace[-1])\n",
    "    \n",
    "    # Compute the dip direction\n",
    "    dip = flt.dip\n",
    "    dip_dir = (azim + 90) % 360\n",
    "\n",
    "    if not hasattr(flt, 'lower_seismogenic_depth'):\n",
    "        flt.lower_seismogenic_depth = float(metys.g_prj.mod[model_key]['sfs_default_lower_seismogenic_depth'])\n",
    "     \n",
    "    if not hasattr(flt, 'upper_seismogenic_depth'):\n",
    "        flt.upper_seismogenic_depth = float(metys.g_prj.mod[model_key]['sfs_default_upper_seismogenic_depth'])\n",
    "    \n",
    "    seism_thickness = flt.lower_seismogenic_depth - flt.upper_seismogenic_depth\n",
    "    \n",
    "    # Horizontal distance\n",
    "    h_dist = seism_thickness / scipy.tan(scipy.radians(dip))\n",
    "    \n",
    "    # Compute the bottom trace\n",
    "    xb = xtrace\n",
    "    yb = ytrace\n",
    "    for x, y in zip (xtrace[::-1], ytrace[::-1]):\n",
    "        nx, ny = point_at(x, y, dip_dir, h_dist)\n",
    "        xb.append(nx)\n",
    "        yb.append(ny)\n",
    "    \n",
    "    # Create the polygon geometry\n",
    "    pnt_list = []\n",
    "    for x, y in zip(xb, yb):\n",
    "        pnt_list.append((x,y))\n",
    "\n",
    "    return pnt_list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def get_polygon_from_simple_fault(flt):\n",
    "\n",
    "    xtrace = []\n",
    "    ytrace = []\n",
    "    for pnt in flt.trace:\n",
    "        xtrace.append(pnt.longitude)\n",
    "        ytrace.append(pnt.latitude)\n",
    "    \n",
    "    # Get strike direction\n",
    "    azim = azimuth(xtrace[0], ytrace[0],\n",
    "                   xtrace[-1], ytrace[-1])\n",
    "    \n",
    "    if not hasattr(flt, 'lower_seismogenic_depth'):\n",
    "        flt.lower_seismogenic_depth = float(metys.g_prj.mod[model_key]['sfs_default_lower_seismogenic_depth'])\n",
    "     \n",
    "    if not hasattr(flt, 'upper_seismogenic_depth'):\n",
    "        flt.upper_seismogenic_depth = float(metys.g_prj.mod[model_key]['sfs_default_upper_seismogenic_depth'])\n",
    "    \n",
    "    # Compute the dip direction\n",
    "    dip = flt.dip\n",
    "    dip_dir = (azim + 90) % 360\n",
    "    seism_thickness = flt.upper_seismogenic_depth - flt.lower_seismogenic_depth\n",
    "    \n",
    "    # Horizontal distance\n",
    "    h_dist = seism_thickness / scipy.tan(scipy.radians(dip))\n",
    "    \n",
    "    # Compute the bottom trace\n",
    "    xb = xtrace\n",
    "    yb = ytrace\n",
    "    for x, y in zip (xtrace[::-1], ytrace[::-1]):\n",
    "        nx, ny = point_at(x, y, dip_dir, h_dist)\n",
    "        xb.append(nx)\n",
    "        yb.append(ny)\n",
    "    \n",
    "    # Create the polygon geometry\n",
    "    pnt_list = []\n",
    "    for x, y in zip(xb, yb):\n",
    "        pnt_list.append((x,y))\n",
    "\n",
    "    return pnt_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "area_discretization = 10 # In [km]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dilated polygon around the area source\n",
    "NOTE: We don't necessarily need to use the polygon of the area source. In a future version the polygon must be defined in the configuration file or computed automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_polygon = src.polygon.dilate(100)\n",
    "polygon_mesh = new_polygon.discretize(area_discretization)\n",
    "print 'Number of points: %d' % (len(polygon_mesh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the earthquakes within the dilated polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# First we get the earthquakes of the catalogue within the dilated polygon \n",
    "pickle_filename = os.path.join(metys.g_prj.folder, '%s_catalogue_declustered.pkl' % model_key)\n",
    "fin = open(pickle_filename, 'rb') \n",
    "catalogue = pickle.load(fin)\n",
    "fin.close()\n",
    "print 'The catalogue contains %d earthquakes' % (len(catalogue.data['magnitude']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Then we create the subcatalogue for the dilated polygon\n",
    "cutoff_magnitude = float(metys.g_prj.mod[model_key]['catalogue_cutoff_magnitude'])\n",
    "fcatal = create_catalogue([src], catalogue, polygon=new_polygon)\n",
    "selector = CatalogueSelector(catalogue, create_copy=False)\n",
    "selector.within_magnitude_range(cutoff_magnitude, 10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute scaling factor based on completeness - For the time being we don't consider this.\n",
    "scalf = numpy.ones((len(fcatal.data['magnitude'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "smooth = {'gaussian': [50, 25, 0.2],\n",
    "          'gaussian': [20, 25, 0.8]}\n",
    "smooth = Smoothing(fcatal, polygon_mesh, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "values = smooth.gaussian(50, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.scatter(smooth.mesh.lons, smooth.mesh.lats, c=values, vmin=0, vmax=0.4, marker='s', s=15)\n",
    "plt.plot(src.polygon.lons, src.polygon.lats, 'r')\n",
    "plt.plot(fcatal.data['longitude'], fcatal.data['latitude'], 'og', mfc='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm tmp*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the nodes of the grid within the area source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idxp = smooth.get_points_in_polygon(src.polygon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.scatter(smooth.mesh.lons[idxp], smooth.mesh.lats[idxp], vmin=0, vmax=0.4, c=values[idxp], marker='s', s=15)\n",
    "plt.plot(src.polygon.lons, src.polygon.lats, 'r')\n",
    "for iii, key in enumerate(sorted(src.ids_faults_inside.keys())): \n",
    "    tsrc = fsources[key] \n",
    "    coord = numpy.array(get_polygon_from_simple_fault(tsrc))\n",
    "    plt.plot(coord[:,0], coord[:,1], 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning seismicity to the source\n",
    "The redistribution of seismicity to the source is done for each cell using as a scaling factor the ratio of the value assigned to the node and the sum of the values of all the nodes within the area source. Note that the mfd assigned to the area source must be an EvenlyDiscretisedMFD instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaling_factor = 1./sum(values[idxp])\n",
    "print 'Number of nodes within the area source: %d' % (len(values[idxp]))\n",
    "\n",
    "print src.mfd.get_annual_occurrence_rates()\n",
    "rtes = [aa[1] for aa in src.mfd.get_annual_occurrence_rates()]\n",
    "\n",
    "# mfdpoints is a 2D array with a number of rows equal to the number of points used to \n",
    "# represent the area source\n",
    "mfdpnts = numpy.array([rtes]*len(values))*scaling_factor\n",
    "\n",
    "print mfdpnts.shape\n",
    "\n",
    "xxx = numpy.tile(values, (mfdpnts.shape[1], 1)).T\n",
    "mfdpnts = mfdpnts * xxx\n",
    "\n",
    "mags = []\n",
    "for mag, _ in src.mfd.get_annual_occurrence_rates():\n",
    "    mags.append(mag) \n",
    "    \n",
    "print 'done A'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cutting the MFDs of the point sources close to faults"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "lomin = min(smooth.mesh.lons)-1\n",
    "lomax = max(smooth.mesh.lons)+1\n",
    "lamin = min(smooth.mesh.lats)-1\n",
    "lamax = max(smooth.mesh.lats)+1\n",
    "\n",
    "fig = plt.figure(figsize=(20,16))\n",
    "m = Basemap(llcrnrlon=lomin,\n",
    "            llcrnrlat=lamin,\n",
    "            urcrnrlon=lomax,\n",
    "            urcrnrlat=lamax,\n",
    "            resolution='i',\n",
    "            projection='tmerc',\n",
    "            lon_0=106,\n",
    "            lat_0=28)\n",
    "\n",
    "m.shadedrelief()\n",
    "\n",
    "x, y = m(smooth.mesh.lons, smooth.mesh.lats)\n",
    "rtes = numpy.sum(mfdpnts, axis=1)\n",
    "print rtes.shape\n",
    "plt.scatter(x[idxp], y[idxp], s=9, marker='s', c=rtes, lw=0.)\n",
    "\n",
    "parallels = numpy.arange(lamin, lamax, 5.)\n",
    "m.drawparallels(parallels,labels=[False,True,True,False])\n",
    "meridians = numpy.arange(90, lomax, 5.)\n",
    "m.drawmeridians(meridians,labels=[True,False,False,True])\n",
    "\n",
    "jjj = numpy.nonzero(chng > 0)\n",
    "plt.plot(x[jjj], y[jjj], 'x', lw=0.8, alpha=0.4, ms=8, markerfacecolor='None', markeredgecolor='purple')\n",
    "\n",
    "x, y = m(src.polygon.lons, src.polygon.lats)        \n",
    "plt.plot(x, y, 'g', lw=3)\n",
    "\n",
    "for iii, key in enumerate(sorted(src.ids_faults_inside.keys())):     \n",
    "    tsrc = fsources[key]\n",
    "    coord = numpy.array(get_polygon_from_simple_fault(tsrc))\n",
    "    x, y = m(coord[:,0], coord[:,1])\n",
    "    if 'mfd' in tsrc.__dict__ and tsrc.mfd is not None:\n",
    "        plt.plot(x, y, 'r', lw=3)\n",
    "    else:\n",
    "        plt.plot(x, y, '-', color='pink')\n",
    "        \n",
    "print 'done B'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create the nrml sources "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from openquake.hazardlib.scalerel.wc1994 import WC1994\n",
    "from openquake.hazardlib.tom import PoissonTOM\n",
    "from openquake.hazardlib.pmf import PMF\n",
    "from openquake.hazardlib.geo.nodalplane import NodalPlane \n",
    "\n",
    "nrmls = [] \n",
    "rupture_mesh_spacing = 2.5\n",
    "magnitude_scaling_relationship = WC1994()\n",
    "rupture_aspect_ratio = 2.0\n",
    "temporal_occurrence_model = PoissonTOM(1.)\n",
    "nodal_plane_distribution = PMF([(1.0, NodalPlane(0, 90, -90))])\n",
    "hypocenter_distribution = PMF([(1.0, 7.5)])\n",
    "\n",
    "for eee, iii in enumerate(idxp):\n",
    "    jjj = numpy.nonzero(mfdpnts[iii, :] > 0)\n",
    "    \n",
    "    if len(list(mfdpnts[iii, jjj][0])) > 0:\n",
    "        tmfd = EvenlyDiscretizedMFD(src.mfd.min_mag, src.mfd.bin_width, list(mfdpnts[iii, jjj][0]))\n",
    "\n",
    "        points = PointSource(\n",
    "            source_id='%s-%d' % (src.source_id, eee), \n",
    "            name='', \n",
    "            tectonic_region_type=src.tectonic_region_type,\n",
    "            mfd=tmfd, \n",
    "            rupture_mesh_spacing=rupture_mesh_spacing,\n",
    "            magnitude_scaling_relationship=magnitude_scaling_relationship, \n",
    "            rupture_aspect_ratio=rupture_aspect_ratio,\n",
    "            temporal_occurrence_model=temporal_occurrence_model,\n",
    "            upper_seismogenic_depth=0.0, \n",
    "            lower_seismogenic_depth=src.lower_seismogenic_depth,\n",
    "            location=Point(smooth.mesh.lons[iii], smooth.mesh.lats[iii]), \n",
    "            nodal_plane_distribution=nodal_plane_distribution, \n",
    "            hypocenter_distribution=hypocenter_distribution\n",
    "            )\n",
    "        nrmls.append(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buff = 2.0\n",
    "jjj = numpy.nonzero(numpy.array(mags) > 6.5)\n",
    "chng = numpy.zeros_like((values))\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "\n",
    "if hasattr(src, 'ids_faults_inside'):\n",
    "    for iii, key in enumerate(sorted(src.ids_faults_inside.keys())): \n",
    "        \n",
    "        # Getting the fault source\n",
    "        tsrc = fsources[key]\n",
    "        print 'Source:', key\n",
    "        \n",
    "        if 'mfd' in tsrc.__dict__ and tsrc.mfd is not None:\n",
    "        \n",
    "            lons, lats = get_xy(tsrc.trace) \n",
    "\n",
    "            # Create the polygon representing the surface projection of the fault\n",
    "            # surface\n",
    "            coord = numpy.array(get_polygon_from_simple_fault(tsrc))\n",
    "\n",
    "            min_lon = numpy.min(lons)-buff\n",
    "            max_lon = numpy.max(lons)+buff\n",
    "            min_lat = numpy.min(lats)-buff\n",
    "            max_lat = numpy.max(lats)+buff\n",
    "\n",
    "            idxs = list(smooth.rtree.intersection((min_lon, min_lat, max_lon, max_lat)))\n",
    "\n",
    "            iii = get_idx_points_inside_polygon(smooth.mesh.lons[idxs], \n",
    "                                                smooth.mesh.lats[idxs],\n",
    "                                                list(coord[:,0]), \n",
    "                                                list(coord[:,1]), \n",
    "                                                idxs,\n",
    "                                                15000.0) \n",
    "            \n",
    "            for tidx in iii:\n",
    "                plt.plot(smooth.mesh.lons[tidx], smooth.mesh.lats[tidx], 'o')\n",
    "                mfdpnts[tidx, jjj] = 0.\n",
    "                chng[tidx] = 1.\n",
    "\n",
    "plt.plot(src.polygon.lons, src.polygon.lats, 'g', lw=4)\n",
    "for iii, key in enumerate(sorted(src.ids_faults_inside.keys())): \n",
    "        tsrc = fsources[key]\n",
    "        lons, lats = get_xy(tsrc.trace) \n",
    "        coord = numpy.array(get_polygon_from_simple_fault(tsrc))\n",
    "        plt.plot(coord[:,0], coord[:,1], 'r')\n",
    "\n",
    "print 'done C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from openquake.hazardlib.sourceconverter import SourceGroup\n",
    "def get_groups(srcl):\n",
    "    grps = {}\n",
    "    for src in srcl:\n",
    "        if src.tectonic_region_type in grps.keys():\n",
    "            grps[src.tectonic_region_type].append(src)\n",
    "        else:\n",
    "            grps[src.tectonic_region_type] = [src]\n",
    "    return [SourceGroup(key, sources=grps[key]) for key in grps.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "from openquake.baselib.general import groupby\n",
    "\n",
    "# Write the nrml file\n",
    "model_key = metys.g_prj.models.current \n",
    "model_dir = os.path.join(metys.g_prj.folder, 'nrml/%s' % model_key)\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "from openquake.hazardlib.sourcewriter import write_source_model\n",
    "from openquake.hazardlib.sourceconverter import SourceGroup\n",
    "\n",
    "sgrps = get_groups(nrmls)\n",
    "\n",
    "model_name = 'gss_%s.xml' % (src.source_id)\n",
    "out_model_name = os.path.join(model_dir, model_name)\n",
    "_ = write_source_model(out_model_name, sgrps, 'Model %s' % (model_key))\n",
    "\n",
    "print 'Created %s ' % (out_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
