{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catalogue pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named hmtk.seismicity.occurrence.weichert",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e65bb48f2b87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mhmtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseismicity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moccurrence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweichert\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWeichert\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhmtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseismicity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompleteness\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomp_stepp_1971\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStepp1971\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhmtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseismicity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompleteness\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_stepp_1972\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcreate_stepp_plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named hmtk.seismicity.occurrence.weichert"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "#sys.path.append('./../../../../hmtk/')\n",
    "#sys.path.append('./../../../../oq-hazardlib/')\n",
    "#sys.path.append('/home/openquake/GEM/oq-mbt/')\n",
    "\n",
    "import h5py\n",
    "import numpy\n",
    "import subprocess\n",
    "import cPickle as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from copy import deepcopy\n",
    "\n",
    "from hmtk.seismicity.occurrence.weichert import Weichert\n",
    "from hmtk.seismicity.completeness.comp_stepp_1971 import Stepp1971 \n",
    "from hmtk.plotting.seismicity.completeness.plot_stepp_1972 import create_stepp_plot\n",
    "from hmtk.plotting.seismicity.catalogue_plots import (plot_magnitude_time_scatter, \n",
    "                                                      plot_magnitude_time_density)\n",
    "from hmtk.parsers.catalogue.csv_catalogue_parser import CsvCatalogueParser\n",
    "from hmtk.seismicity.selector import CatalogueSelector\n",
    "from hmtk.seismicity.declusterer.dec_gardner_knopoff import GardnerKnopoffType1\n",
    "from hmtk.seismicity.declusterer.distance_time_windows import GardnerKnopoffWindow"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from oqmbt.oqt_project import OQtProject, OQtModel, OQtSource\n",
    "project_pickle_filename = os.environ.get('OQMBT_PROJECT')\n",
    "oqtkp = OQtProject.load_from_file(project_pickle_filename)\n",
    "oqtkp.directory = os.path.dirname(project_pickle_filename)\n",
    "model_id = oqtkp.active_model_id\n",
    "model = oqtkp.models[model_id]\n",
    "catalogue_csv_filename = os.path.join(oqtkp.directory, getattr(model,'catalogue_csv_filename'))\n",
    "print 'Reading: %s' % (catalogue_csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named metys",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-8c616546b599>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmetys\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mg_prj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# -- Configuration parameters --\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcutoff_magnitude\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg_prj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ASC'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'catalogue_cutoff_magnitude'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbinwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg_prj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ASC'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mfd_binwidth'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named metys"
     ]
    }
   ],
   "source": [
    "from metys import g_prj\n",
    "\n",
    "# -- Configuration parameters --\n",
    "cutoff_magnitude = float(g_prj.mod['ASC']['catalogue_cutoff_magnitude'])\n",
    "binwidth = float(g_prj.mod['ASC']['mfd_binwidth'])\n",
    "print 'MFD bin width    : %.2f' % (binwidth)\n",
    "print 'Magnitude cutoff : %.2f' % (cutoff_magnitude)\n",
    "\n",
    "# -- Load data --\n",
    "catalogue = g_prj.mod['ASC']['catalogue_from_csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main settings"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Cutoff magnitude i.e. lowest magnitude treshold. All the events below this threshold \n",
    "# are filtered out at the beginning of the processing workflow\n",
    "cutoff_magnitude = float(model.catalogue_cutoff_magnitude)\n",
    "# Width of bins used to discretise the MFDs\n",
    "binwidth = float(model.mfd_binwidth)\n",
    "print 'MFD bin width    : %.2f' % (binwidth)\n",
    "print 'Magnitude cutoff : %.2f' % (cutoff_magnitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read catalogue\n",
    "Read the catalogue from the .csv file and remove events below the cutoff magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selector = CatalogueSelector(catalogue, create_copy=False)\n",
    "selector.within_magnitude_range(cutoff_magnitude, 10.)\n",
    "selector.within_depth_range(300, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print numpy.min(catalogue.data['depth'])\n",
    "print numpy.max(catalogue.data['depth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catalogue declustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distance_time_wind = GardnerKnopoffWindow()\n",
    "config = {'time_distance_window': distance_time_wind, 'fs_time_prop': .9}\n",
    "declusterer = GardnerKnopoffType1()\n",
    "vcl, flag = declusterer.decluster(catalogue, config)\n",
    "catalogue_original = deepcopy(catalogue)\n",
    "print 'Original number of events', catalogue_original.get_number_events()\n",
    "catalogue.select_catalogue_events(numpy.where(flag == 0)[0])\n",
    "print 'Number of mainshocks:', len(catalogue.data['magnitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catalogue plotting\n",
    "### Catalogue map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 1:\n",
    "    \n",
    "    lomin = 98\n",
    "    lomax = 108\n",
    "    lamin = 20\n",
    "    lamax = 34    \n",
    "    \n",
    "    fig = plt.figure(figsize=(20,16))\n",
    "    m = Basemap(llcrnrlon=lomin,\n",
    "                llcrnrlat=lamin,\n",
    "                urcrnrlon=lomax,\n",
    "                urcrnrlat=lamax,\n",
    "                resolution='i',\n",
    "                projection='tmerc',\n",
    "                lon_0=106,\n",
    "                lat_0=28)\n",
    "\n",
    "    m.shadedrelief()\n",
    "    \n",
    "    parallels = numpy.arange(lamin, lamax, 5.)\n",
    "    m.drawparallels(parallels,labels=[False,True,True,False], fontsize=16)\n",
    "    meridians = numpy.arange(90, lomax, 5.)\n",
    "    m.drawmeridians(meridians,labels=[True,False,False,True], fontsize=16)\n",
    "    \n",
    "    # Coordinate conversion\n",
    "    idx = numpy.nonzero(flag!=0)[0]\n",
    "    x, y = m(catalogue.data['longitude'], catalogue.data['latitude'])\n",
    "    \n",
    "    print idx.shape\n",
    "    print x.shape\n",
    "\n",
    "    # catalogue    \n",
    "    x, y = m(catalogue.data['longitude'], catalogue.data['latitude'])\n",
    "    plt.plot(x, y, 'o', linewidth=6, alpha=0.4, color='blue')\n",
    "    #plt.scatter(x, y, catalogue.data['magnitude'], marker='o', linewidth=0.5, alpha=0.4, edgecolors='none')\n",
    "    \n",
    "    x, y = m(catalogue_original.data['longitude'], catalogue_original.data['latitude'])\n",
    "    plt.plot(x[idx], y[idx], 'x', linewidth=.5, alpha=0.8, color='red') \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "if 1:\n",
    "    \n",
    "    import cartopy\n",
    "    import cartopy.crs as ccrs\n",
    "    from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 14), dpi=300)\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "    ax.stock_img()\n",
    "    \n",
    "    if 'map_limits' in model.__dict__:\n",
    "        limits = model.map_limits\n",
    "        tickspacing = model.map_tick_spacing\n",
    "    else:\n",
    "        limits = [min(catalogue.data['longitude']), min(catalogue.data['latitude']), \n",
    "                  max(catalogue.data['longitude']), max(catalogue.data['latitude'])]\n",
    "        if limits[2]-limits[0] > 20:\n",
    "            tickspacing = 10\n",
    "        else:\n",
    "            tickspacing = 5\n",
    "    \n",
    "    ax.coastlines()\n",
    "    # ax.add_feature(cartopy.feature.OCEAN, zorder=0)\n",
    "    # set the area for the plot\n",
    "    ax.set_extent([limits[0], limits[2], limits[1], limits[3]], ccrs.Geodetic())\n",
    "    \n",
    "    xlo = numpy.floor(limits[0]/10)*10\n",
    "    ylo = numpy.round(limits[1]/10)*10\n",
    "    ax.set_xticks(numpy.arange(xlo, limits[2], tickspacing), crs=ccrs.PlateCarree())\n",
    "    ax.set_yticks(numpy.arange(ylo, limits[3], tickspacing), crs=ccrs.PlateCarree())\n",
    "    \n",
    "    idx = numpy.nonzero(flag!=0)\n",
    "\n",
    "    # catalogue    \n",
    "    ax.plot(catalogue.data['longitude'], catalogue.data['latitude'], 'o',\n",
    "            linewidth=6, alpha=0.4, transform=ccrs.Geodetic(), color='blue')\n",
    "\n",
    "    ax.plot(catalogue_original.data['longitude'][idx], \n",
    "            catalogue_original.data['latitude'][idx], 'x',\n",
    "            linewidth=.5, alpha=0.8, transform=ccrs.Geodetic(), color='red')   \n",
    "\n",
    "                                                 \n",
    "    # grid\n",
    "    #ax.gridlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catalogue completeness analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = {'magnitude_bin': .5, 'time_bin': 10., 'increment_lock': True}\n",
    "stepp = Stepp1971()\n",
    "compl_table = stepp.completeness(catalogue, config)          \n",
    "subprocess.call('rm aa', shell=True)\n",
    "#create_stepp_plot(stepp, 'aa')\n",
    "subprocess.call('rm aa', shell=True)\n",
    "# info\n",
    "print 'Maximum magnitude is: ', max(catalogue.data['magnitude'])\n",
    "print 'The catalogue contains %d events' % (catalogue.get_number_events())\n",
    "print 'Completeness table: \\n'\n",
    "# Display html\n",
    "for line in compl_table:\n",
    "    print '%.2f, %.2f' % (line[0], line[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_magnitude_time_density(catalogue, mag_int=0.1, time_int=2.5, normalisation=True, \n",
    "                            bootstrap=0, completeness=compl_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = numpy.nonzero(compl_table[:,1] < numpy.max(catalogue.data['magnitude']))\n",
    "weichert_config = {'magnitude_interval': 0.1, \n",
    "                   'reference_magnitude': 0.0}\n",
    "weichert = Weichert()\n",
    "bval_wei, sigmab, aval_wei, sigmaa = weichert.calculate(catalogue, weichert_config, completeness=compl_table)\n",
    "print 'bval: %.3f (sigma=%.3f)' % (bval_wei, sigmab)\n",
    "print 'aval: %.3f (sigma=%.3f)' % (aval_wei, sigmaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hmtk.plotting.seismicity.occurrence.recurrence_plot import plot_trunc_gr_model\n",
    "#plot_trunc_gr_model(aval_wei, bval_wei, 5.0, 9.5, 0.1, catalogue=catalogue,\n",
    "#        completeness=compl_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Saving catalogue pickle file and updating the project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_lab = re.sub('\\s', '_', oqtkp.models[model_id].name).lower()\n",
    "output_path = os.path.join(oqtkp.directory, '%s_catalogue.pkl' % model_lab)\n",
    "fou = open(output_path,'wb') \n",
    "pickle.dump(catalogue, fou)\n",
    "fou.close()\n",
    "print 'Catalogue dataset saved into file: \\n%s' % (output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving completeness into hdf5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = os.path.join(oqtkp.directory, oqtkp.compl_hdf5_filename)\n",
    "fhdf5 = h5py.File(filename, 'a')\n",
    "print 'Saving data into %s' % (filename)\n",
    "dataset_name = 'whole_catalogue'\n",
    "# Update/create group\n",
    "if model_id in fhdf5.keys():\n",
    "    print 'Group exists %s ' % (model_id)\n",
    "    grp = fhdf5[model_id]\n",
    "else:\n",
    "    print 'Creating group: %s' % (model_id)\n",
    "    grp = fhdf5.create_group(model_id)\n",
    "# Update/create dataset\n",
    "if dataset_name in grp:\n",
    "    del fhdf5[model_id][dataset_name]\n",
    "    print 'Updating dataset: %s' % (dataset_name)\n",
    "    dataset = grp.create_dataset(dataset_name, data=compl_table)\n",
    "else:\n",
    "    print 'Creating dataset: %s' % (dataset_name)\n",
    "    dataset = grp.create_dataset(dataset_name, data=compl_table)\n",
    "fhdf5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oqtkp.models[model_id].declustered_catalogue_pickle_filename = os.path.relpath(output_path, oqtkp.directory)\n",
    "oqtkp.save()\n",
    "print oqtkp.models[model_id].declustered_catalogue_pickle_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = oqtkp.models[model_id]\n",
    "model.get_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print completed execution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
