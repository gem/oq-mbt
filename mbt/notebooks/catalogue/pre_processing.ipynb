{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catalogue pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cleaner avoid to restart kernel for each code modification, use it just when alone\n",
    "from cleaner import modules_cleaner ; modules_cleaner()\n",
    "# load current project if secondary ipynb runned alone\n",
    "import metys; metys.Metys.secondary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import re\n",
    "import os\n",
    "import numpy\n",
    "import h5py\n",
    "import subprocess\n",
    "import cPickle as pickle\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "from hmtk.seismicity.occurrence.weichert import Weichert\n",
    "from hmtk.plotting.seismicity.occurrence.recurrence_plot import plot_trunc_gr_model\n",
    "\n",
    "from hmtk.seismicity.completeness.comp_stepp_1971 import Stepp1971 \n",
    "from hmtk.plotting.seismicity.completeness.plot_stepp_1972 import create_stepp_plot\n",
    "from hmtk.plotting.seismicity.catalogue_plots import (plot_magnitude_time_scatter, \n",
    "                                                      plot_magnitude_time_density)\n",
    "\n",
    "from hmtk.seismicity.selector import CatalogueSelector\n",
    "from hmtk.seismicity.declusterer.dec_gardner_knopoff import GardnerKnopoffType1\n",
    "from hmtk.seismicity.declusterer.distance_time_windows import GardnerKnopoffWindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    plot_figures\n",
    "except: \n",
    "    plot_figures = False\n",
    "    \n",
    "try:\n",
    "    print_log\n",
    "except: \n",
    "    print_log = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read current model and fix configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_key = metys.g_prj.models.current \n",
    "cutoff_magnitude = float(metys.g_prj.mod[model_key]['catalogue_cutoff_magnitude'])\n",
    "cutoff_depth = float(metys.g_prj.mod[model_key]['catalogue_cutoff_depth'])\n",
    "binwidth = float(metys.g_prj.mod[model_key]['mfd_binwidth'])\n",
    "if print_log:\n",
    "    print 'MFD bin width    : %.2f' % (binwidth)\n",
    "    print 'Magnitude cutoff : %.2f' % (cutoff_magnitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "catalogue = metys.g_prj.mod[model_key]['earthquake_catalogue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selector = CatalogueSelector(catalogue, create_copy=False)\n",
    "selector.within_magnitude_range(cutoff_magnitude, 10.)\n",
    "selector.within_depth_range(300, 0)\n",
    "#\n",
    "if print_log: \n",
    "    print 'Catalogue minimum depth [km]: %.2f ' % numpy.min(catalogue.data['depth'])\n",
    "    print 'Catalogue maximum depth [km]: %.2f ' % numpy.max(catalogue.data['depth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distance_time_wind = GardnerKnopoffWindow()\n",
    "config = {'time_distance_window': distance_time_wind, 'fs_time_prop': .9}\n",
    "\n",
    "declusterer = GardnerKnopoffType1()\n",
    "vcl, flag = declusterer.decluster(catalogue, config)\n",
    "catalogue_original = deepcopy(catalogue)\n",
    "if print_log:\n",
    "    print 'Original number of events', catalogue_original.get_number_events()\n",
    "catalogue.select_catalogue_events(numpy.where(flag == 0)[0])\n",
    "if print_log:\n",
    "    print 'Number of mainshocks:', len(catalogue.data['magnitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Computing geograohic limits of the catalogue\n",
    "lomin = min(catalogue.data['longitude'])\n",
    "lomax = max(catalogue.data['longitude'])\n",
    "lamin = min(catalogue.data['latitude'])\n",
    "lamax = max(catalogue.data['latitude'])    \n",
    "lon_0 = sum([lomin,lomax])/2\n",
    "lat_0 = sum([lamin,lamax])/2\n",
    "\n",
    "if plot_figures: \n",
    "    fig = plt.figure(figsize=(20,16))\n",
    "    m = Basemap(llcrnrlon=lomin,\n",
    "                llcrnrlat=lamin,\n",
    "                urcrnrlon=lomax,\n",
    "                urcrnrlat=lamax,\n",
    "                resolution='i',\n",
    "                projection='tmerc',\n",
    "                lon_0=lon_0,\n",
    "                lat_0=lat_0)\n",
    "\n",
    "    m.shadedrelief()\n",
    "    \n",
    "    parallels = numpy.arange(lamin, lamax, 5.)\n",
    "    m.drawparallels(parallels,labels=[False,True,True,False], fontsize=16)\n",
    "    meridians = numpy.arange(lomin, lomax, 5.)\n",
    "    m.drawmeridians(meridians,labels=[True,False,False,True], fontsize=16)\n",
    "    \n",
    "    # Coordinate conversion\n",
    "    idx = numpy.nonzero(flag!=0)[0]\n",
    "    x, y = m(catalogue.data['longitude'], catalogue.data['latitude'])\n",
    "\n",
    "    # catalogue    \n",
    "    x, y = m(catalogue.data['longitude'], catalogue.data['latitude'])\n",
    "    plt.plot(x, y, 'o', linewidth=6, alpha=0.4, color='blue')\n",
    "    #plt.scatter(x, y, catalogue.data['magnitude'], marker='o', linewidth=0.5, alpha=0.4, edgecolors='none')\n",
    "    \n",
    "    x, y = m(catalogue_original.data['longitude'], catalogue_original.data['latitude'])\n",
    "    plt.plot(x[idx], y[idx], 'x', linewidth=.5, alpha=0.8, color='red') \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Completeness analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Declustering configuration parameters\n",
    "config = {'magnitude_bin': .5, 'time_bin': 10., 'increment_lock': True}\n",
    "stepp = Stepp1971()\n",
    "compl_table = stepp.completeness(catalogue, config)          \n",
    "subprocess.call('rm aa', shell=True)\n",
    "# Info\n",
    "if print_log:\n",
    "    print 'Maximum magnitude is: ', max(catalogue.data['magnitude'])\n",
    "    print 'The catalogue contains %d events' % (catalogue.get_number_events())\n",
    "    print 'Completeness table: \\n'\n",
    "    # Print completeness table\n",
    "    for line in compl_table:\n",
    "        print '%.2f, %.2f' % (line[0], line[1])\n",
    "# Plot completeness \n",
    "if plot_figures:\n",
    "    ppp = plot_magnitude_time_density(catalogue, mag_int=0.1, time_int=10, normalisation=True, \n",
    "                                      bootstrap=0, completeness=compl_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GR Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = numpy.nonzero(compl_table[:,1] < numpy.max(catalogue.data['magnitude']))\n",
    "weichert_config = {'magnitude_interval': 0.1, \n",
    "                   'reference_magnitude': 0.0}\n",
    "weichert = Weichert()\n",
    "bval_wei, sigmab, aval_wei, sigmaa = weichert.calculate(catalogue, weichert_config, completeness=compl_table)\n",
    "if print_log:\n",
    "    print 'bval: %.3f (sigma=%.3f)' % (bval_wei, sigmab)\n",
    "    print 'aval: %.3f (sigma=%.3f)' % (aval_wei, sigmaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if plot_figures:\n",
    "    plot_trunc_gr_model(aval_wei, bval_wei, 5.0, 8.3, 0.1, catalogue=catalogue,\n",
    "            completeness=compl_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_path = os.path.join(metys.g_prj.folder, '%s_catalogue_declustered.pkl' % model_key)\n",
    "fou = open(output_path,'wb') \n",
    "pickle.dump(catalogue, fou)\n",
    "fou.close()\n",
    "if print_log:\n",
    "    print 'Catalogue dataset saved into file: \\n%s' % (output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving completeness data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = os.path.join(metys.g_prj.folder, 'completeness.hdf5')\n",
    "fhdf5 = h5py.File(filename, 'a')\n",
    "print 'Saving data into %s' % (filename)\n",
    "dataset_name = 'whole_catalogue'\n",
    "# Update/create group\n",
    "if model_key in fhdf5.keys():\n",
    "    if print_log:\n",
    "        print 'Group exists %s ' % (model_key)\n",
    "    grp = fhdf5[model_key]\n",
    "else:\n",
    "    if print_log:\n",
    "        print 'Creating group: %s' % (model_key)\n",
    "    grp = fhdf5.create_group(model_key)\n",
    "# Update/create dataset\n",
    "if dataset_name in grp:\n",
    "    del fhdf5[model_key][dataset_name]\n",
    "    if print_log:\n",
    "        print 'Updating dataset: %s' % (dataset_name)\n",
    "    dataset = grp.create_dataset(dataset_name, data=compl_table)\n",
    "else:\n",
    "    if print_log:\n",
    "        print 'Creating dataset: %s' % (dataset_name)\n",
    "    dataset = grp.create_dataset(dataset_name, data=compl_table)\n",
    "fhdf5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
